{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zarif123/497-DLNLP-HW2/blob/main/generate_ran_test_latest_choice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "AkEzGPQ4XZoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "onPXFTz0Xek_",
        "outputId": "c2675b97-7d5e-4b42-8682-b3996ae709cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'generate_20.pth'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkptzdQ8iSJ4",
        "outputId": "817fee53-03b0-4d12-f429-e95a2abe67d7"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertModel, GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "CHkzfMQmXXhG"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Loop"
      ],
      "metadata": {
        "id": "FL3jJ6QeI1hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, optimizer, tokenizer, train, num_choices, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1} ///////////////////////////////\")\n",
        "\n",
        "        train_len = len(train)\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for train_i in range(train_len):\n",
        "            observation = train[train_i]\n",
        "\n",
        "            # for choice_i in range(num_choices):\n",
        "            #     context = observation[choice_i][0]\n",
        "            #     label = observation[choice_i][1]\n",
        "            #     contexts.append(context)\n",
        "            #     labels.append(label)\n",
        "            #     mask[choice_i][label] = 1\n",
        "            \n",
        "            inputs = tokenizer(observation, return_tensors=\"pt\")\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(**inputs, labels=inputs['input_ids'])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = outputs[0]\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if train_i % 1000 == 0:\n",
        "                print(train_i, \"/\", train_len)\n",
        "        \n",
        "        average_loss = total_loss / train_len\n",
        "        print(f\"Average Loss: {average_loss}\")\n",
        "\n",
        "        torch.save(model.state_dict(), path)\n",
        "            \n"
      ],
      "metadata": {
        "id": "rptL9oaWJBaV"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Loop"
      ],
      "metadata": {
        "id": "DlER2Y9WXoOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_choice(tokens):\n",
        "  try:\n",
        "    a_index = tokens.index('A')\n",
        "  except ValueError :\n",
        "    a_index = -float('inf')\n",
        "  try:\n",
        "    b_index = tokens.index('B')\n",
        "  except ValueError :\n",
        "    b_index = -float('inf')\n",
        "  try:\n",
        "    c_index = tokens.index('C')\n",
        "  except ValueError :\n",
        "    c_index = -float('inf')\n",
        "  try:\n",
        "    d_index = tokens.index('D')\n",
        "  except ValueError :\n",
        "    d_index = -float('inf')\n",
        "  #print(a_index, b_index, c_index, d_index)\n",
        "  return len(tokens) - min(a_index, b_index, c_index, d_index) - 1"
      ],
      "metadata": {
        "id": "AovbdvLMaXuA"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(model, tokenizer, test):\n",
        "    test_len = len(test)\n",
        "    running_accuracy = 0\n",
        "\n",
        "    for test_i in range(test_len):\n",
        "        observation = test[test_i]\n",
        "        \n",
        "        inputs = tokenizer(observation, return_tensors=\"pt\")\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model.generate(**inputs, max_length=len(inputs['input_ids'][0]) + 10, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        tokens = tokenizer.decode(outputs[0], skip_special_tokens=True).split(' ')\n",
        "        \n",
        "        pred_index = max_choice(list(reversed(tokens)))\n",
        "        if pred_index == -float('inf'):\n",
        "          continue\n",
        "        pred = tokens[pred_index]\n",
        "        real = observation[-1]\n",
        "        # print('PRED: ', pred)\n",
        "        # print('REAL: ', real)\n",
        "        # print('OBS: ', observation)\n",
        "        # print('TOKEN: ', tokens)\n",
        "        if pred == real:\n",
        "            running_accuracy += 1\n",
        "\n",
        "        if test_i % 100 == 0:\n",
        "                print(test_i, \"/\", test_len)\n",
        "                if test_i != 0:\n",
        "                  print(running_accuracy / test_i)\n",
        "        \n",
        "    average_accuracy = running_accuracy / test_len\n",
        "    return average_accuracy\n",
        "    # print(f\"Average Accuracy: {average_accuracy}\")\n"
      ],
      "metadata": {
        "id": "NQoTgTYDXn1c"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find Device"
      ],
      "metadata": {
        "id": "5hL7weSZK9Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "7GppVyVCK_5_"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "klPY3DvMI6Ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "KD28eTADH207"
      },
      "outputs": [],
      "source": [
        "def main():  \n",
        "    torch.manual_seed(0)\n",
        "    answers = ['A','B','C','D']\n",
        "\n",
        "    train = []\n",
        "    test = []\n",
        "    valid = []\n",
        "    \n",
        "    file_name = 'train_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem'] + ' [SEP] '\n",
        "        \n",
        "        for j in range(4):\n",
        "            base = base + result['question']['choices'][j]['label'] + ' ' + result['question']['choices'][j]['text'] + ' '\n",
        "            \n",
        "        base = base + ' [SEP] ' + result['answerKey']\n",
        "        train.append(base)\n",
        "        \n",
        "        # print(obs)\n",
        "        # print(' ')\n",
        "        \n",
        "        # print(result['question']['stem'])\n",
        "        # print(' ',result['question']['choices'][0]['label'],result['question']['choices'][0]['text'])\n",
        "        # print(' ',result['question']['choices'][1]['label'],result['question']['choices'][1]['text'])\n",
        "        # print(' ',result['question']['choices'][2]['label'],result['question']['choices'][2]['text'])\n",
        "        # print(' ',result['question']['choices'][3]['label'],result['question']['choices'][3]['text'])\n",
        "        # print('  Fact: ',result['fact1'])\n",
        "        # print('  Answer: ',result['answerKey'])\n",
        "        # print('  ')\n",
        "                \n",
        "    file_name = 'dev_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem'] + ' [SEP] '\n",
        "        \n",
        "        for j in range(4):\n",
        "            base = base + result['question']['choices'][j]['label'] + ' ' + result['question']['choices'][j]['text'] + ' '\n",
        "            \n",
        "        base = base + ' [SEP] ' + result['answerKey']\n",
        "        valid.append(base)\n",
        "        \n",
        "    file_name = 'test_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem'] + ' [SEP] '\n",
        "        \n",
        "        for j in range(4):\n",
        "            base = base + result['question']['choices'][j]['label'] + ' ' + result['question']['choices'][j]['text'] + ' '\n",
        "            \n",
        "        base = base + ' [SEP] ' + result['answerKey']\n",
        "        test.append(base)\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
        "    \n",
        "    model = model.to(device)\n",
        "#    Add code to fine-tune and test your MCQA classifier.\n",
        "    \n",
        "\n",
        "    # Use to toggle between training and testing\n",
        "    is_training = False\n",
        "    is_zero_shot = False\n",
        "\n",
        "    if is_training:\n",
        "        train_loop(model, optimizer, tokenizer, train, 4, 5)\n",
        "    else:\n",
        "        if not is_zero_shot:\n",
        "            model.load_state_dict(torch.load(path))\n",
        "            model.eval()\n",
        "\n",
        "        av_valid_acc = test_loop(model, tokenizer, valid)\n",
        "        print(f\"Valid Average Accuracy: {av_valid_acc}\")\n",
        "\n",
        "        av_test_acc = test_loop(model, tokenizer, test)\n",
        "        print(f\"Test Average Accuracy: {av_test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdvhAG-7IWUi",
        "outputId": "942ba129-d723-4f83-f452-94eb0ddb891a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 500\n",
            "100 / 500\n",
            "0.39\n",
            "200 / 500\n",
            "0.385\n",
            "300 / 500\n",
            "0.42\n",
            "400 / 500\n",
            "0.435\n",
            "Valid Average Accuracy: 0.43\n",
            "0 / 500\n",
            "100 / 500\n",
            "0.28\n",
            "200 / 500\n",
            "0.34\n",
            "300 / 500\n",
            "0.37333333333333335\n",
            "400 / 500\n",
            "0.3925\n",
            "Test Average Accuracy: 0.384\n"
          ]
        }
      ]
    }
  ]
}