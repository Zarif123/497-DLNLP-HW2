{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zarif123/497-DLNLP-HW2/blob/main/generate_ran_test_second_last.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "AkEzGPQ4XZoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "onPXFTz0Xek_",
        "outputId": "d9c3bc14-e49d-434f-9184-eceb84d9798d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'generate (2).pth'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkptzdQ8iSJ4",
        "outputId": "4db01e4e-ccb0-48c5-f3da-15a34328e73f"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertModel, GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "CHkzfMQmXXhG"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Loop"
      ],
      "metadata": {
        "id": "FL3jJ6QeI1hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, optimizer, tokenizer, train, num_choices, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1} ///////////////////////////////\")\n",
        "\n",
        "        train_len = len(train)\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for train_i in range(train_len):\n",
        "            observation = train[train_i]\n",
        "\n",
        "            # for choice_i in range(num_choices):\n",
        "            #     context = observation[choice_i][0]\n",
        "            #     label = observation[choice_i][1]\n",
        "            #     contexts.append(context)\n",
        "            #     labels.append(label)\n",
        "            #     mask[choice_i][label] = 1\n",
        "            \n",
        "            inputs = tokenizer(observation, return_tensors=\"pt\")\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(**inputs, labels=inputs['input_ids'])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = outputs[0]\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if train_i % 1000 == 0:\n",
        "                print(train_i, \"/\", train_len)\n",
        "        \n",
        "        average_loss = total_loss / train_len\n",
        "        print(f\"Average Loss: {average_loss}\")\n",
        "\n",
        "        torch.save(model.state_dict(), path)\n",
        "            \n"
      ],
      "metadata": {
        "id": "rptL9oaWJBaV"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Loop"
      ],
      "metadata": {
        "id": "DlER2Y9WXoOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(model, tokenizer, test):\n",
        "    test_len = len(test)\n",
        "    running_accuracy = 0\n",
        "\n",
        "    for test_i in range(test_len):\n",
        "        observation = test[test_i]\n",
        "        \n",
        "        inputs = tokenizer(observation, return_tensors=\"pt\")\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model.generate(**inputs, max_length=len(inputs['input_ids'][0]) + 1, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        tokens = tokenizer.decode(outputs[0], skip_special_tokens=True).split(' ')\n",
        "        \n",
        "        #pred = tokens[-1]\n",
        "        pred = tokens[-2]\n",
        "        real = observation[-1]\n",
        "        # print('PRED: ', pred)\n",
        "        # print('REAL: ', real)\n",
        "        # print('OBS: ', observation)\n",
        "        # print('TOKEN: ', tokens)\n",
        "        # print('REV TOKENS: ', list(reversed(tokens)))\n",
        "        if pred == real:\n",
        "            running_accuracy += 1\n",
        "        else:\n",
        "          # print('PRED: ', pred)\n",
        "          # print('REAL: ', real)\n",
        "          # print('OBS: ', observation)\n",
        "          # print('TOKEN: ', tokens)\n",
        "\n",
        "        if test_i % 100 == 0:\n",
        "                print(test_i, \"/\", test_len)\n",
        "        \n",
        "    average_accuracy = running_accuracy / test_len\n",
        "    return average_accuracy\n",
        "    # print(f\"Average Accuracy: {average_accuracy}\")\n"
      ],
      "metadata": {
        "id": "NQoTgTYDXn1c"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find Device"
      ],
      "metadata": {
        "id": "5hL7weSZK9Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "7GppVyVCK_5_"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "klPY3DvMI6Ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "KD28eTADH207"
      },
      "outputs": [],
      "source": [
        "def main():  \n",
        "    torch.manual_seed(0)\n",
        "    answers = ['A','B','C','D']\n",
        "\n",
        "    train = []\n",
        "    test = []\n",
        "    valid = []\n",
        "    \n",
        "    file_name = 'train_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem'] + ' [SEP] '\n",
        "        \n",
        "        for j in range(4):\n",
        "            base = base + result['question']['choices'][j]['label'] + ' ' + result['question']['choices'][j]['text'] + ' '\n",
        "            \n",
        "        base = base + ' [SEP] ' + result['answerKey']\n",
        "        train.append(base)\n",
        "        \n",
        "        # print(obs)\n",
        "        # print(' ')\n",
        "        \n",
        "        # print(result['question']['stem'])\n",
        "        # print(' ',result['question']['choices'][0]['label'],result['question']['choices'][0]['text'])\n",
        "        # print(' ',result['question']['choices'][1]['label'],result['question']['choices'][1]['text'])\n",
        "        # print(' ',result['question']['choices'][2]['label'],result['question']['choices'][2]['text'])\n",
        "        # print(' ',result['question']['choices'][3]['label'],result['question']['choices'][3]['text'])\n",
        "        # print('  Fact: ',result['fact1'])\n",
        "        # print('  Answer: ',result['answerKey'])\n",
        "        # print('  ')\n",
        "                \n",
        "    file_name = 'dev_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem'] + ' [SEP] '\n",
        "        \n",
        "        for j in range(4):\n",
        "            base = base + result['question']['choices'][j]['label'] + ' ' + result['question']['choices'][j]['text'] + ' '\n",
        "            \n",
        "        base = base + ' [SEP] ' + result['answerKey']\n",
        "        valid.append(base)\n",
        "        \n",
        "    file_name = 'test_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem'] + ' [SEP] '\n",
        "        \n",
        "        for j in range(4):\n",
        "            base = base + result['question']['choices'][j]['label'] + ' ' + result['question']['choices'][j]['text'] + ' '\n",
        "            \n",
        "        base = base + ' [SEP] ' + result['answerKey']\n",
        "        test.append(base)\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
        "    \n",
        "    model = model.to(device)\n",
        "#    Add code to fine-tune and test your MCQA classifier.\n",
        "    \n",
        "\n",
        "    # Use to toggle between training and testing\n",
        "    is_training = False\n",
        "    is_zero_shot = False\n",
        "\n",
        "    if is_training:\n",
        "        train_loop(model, optimizer, tokenizer, train, 4, 5)\n",
        "    else:\n",
        "        if not is_zero_shot:\n",
        "            model.load_state_dict(torch.load(path))\n",
        "            model.eval()\n",
        "\n",
        "        av_valid_acc = test_loop(model, tokenizer, valid)\n",
        "        print(f\"Valid Average Accuracy: {av_valid_acc}\")\n",
        "\n",
        "        av_test_acc = test_loop(model, tokenizer, test)\n",
        "        print(f\"Test Average Accuracy: {av_test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdvhAG-7IWUi",
        "outputId": "c9cd9e89-0106-4961-f5ee-cb178f35074b"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 500\n",
            "PRED:  [SEP]\n",
            "REAL:  C\n",
            "OBS:  An example of hunting is an otter cracking open clams with a rock [SEP] An animal can hunt by cracking open a [SEP] A claw B house C shell D bone  [SEP] C\n",
            "TOKEN:  ['An', 'example', 'of', 'hunting', 'is', 'an', 'otter', 'cracking', 'open', 'clams', 'with', 'a', 'rock', '[SEP]', 'An', 'animal', 'can', 'hunt', 'by', 'cracking', 'open', 'a', '[SEP]', 'A', 'claw', 'B', 'house', 'C', 'shell', 'D', 'bone', '', '[SEP]', 'CModLoader']\n",
            "PRED:  [SEP]\n",
            "REAL:  C\n",
            "OBS:  dew is formed when water vapor condenses over night [SEP] When vapor condenses overnight it often ends up on [SEP] A bees B clothing C rosebuds D people  [SEP] C\n",
            "TOKEN:  ['dew', 'is', 'formed', 'when', 'water', 'vapor', 'condenses', 'over', 'night', '[SEP]', 'When', 'vapor', 'condenses', 'overnight', 'it', 'often', 'ends', 'up', 'on', '[SEP]', 'A', 'bees', 'B', 'clothing', 'C', 'rosebuds', 'D', 'people', '', '[SEP]', 'Cake']\n",
            "100 / 500\n",
            "PRED:  [SEP]\n",
            "REAL:  B\n",
            "OBS:  an animal requires air for survival [SEP] What animal can live without oxygen [SEP] A shark B Loriciferans C platypus D Turtle  [SEP] B\n",
            "TOKEN:  ['an', 'animal', 'requires', 'air', 'for', 'survival', '[SEP]', 'What', 'animal', 'can', 'live', 'without', 'oxygen', '[SEP]', 'A', 'shark', 'B', 'Loriciferans', 'C', 'platypus', 'D', 'Turtle', '', '[SEP]', 'Baun']\n",
            "200 / 500\n",
            "300 / 500\n",
            "400 / 500\n",
            "PRED:  [SEP]\n",
            "REAL:  B\n",
            "OBS:  a tape measure is used to measure distance [SEP] I need what to calculate the length from my big toe to my little toe? [SEP] A Calculator B Tape Measure C A Graph D A Microscope  [SEP] B\n",
            "TOKEN:  ['a', 'tape', 'measure', 'is', 'used', 'to', 'measure', 'distance', '[SEP]', 'I', 'need', 'what', 'to', 'calculate', 'the', 'length', 'from', 'my', 'big', 'toe', 'to', 'my', 'little', 'toe?', '[SEP]', 'A', 'Calculator', 'B', 'Tape', 'Measure', 'C', 'A', 'Graph', 'D', 'A', 'Microscope', '', '[SEP]', 'Boke']\n",
            "PRED:  [SEP]\n",
            "REAL:  C\n",
            "OBS:  clouds produce rain [SEP] Clouds are [SEP] A Grass B The color green C Quiet heavy D Bricks  [SEP] C\n",
            "TOKEN:  ['clouds', 'produce', 'rain', '[SEP]', 'Clouds', 'are', '[SEP]', 'A', 'Grass', 'B', 'The', 'color', 'green', 'C', 'Quiet', 'heavy', 'D', 'Bricks', '', '[SEP]', 'CSE']\n",
            "PRED:  [SEP]\n",
            "REAL:  C\n",
            "OBS:  a force acting on an object in the opposite direction that the object is moving can cause that object 's speed to decrease in a forward motion [SEP] pushing against a rolling boulder will decrease its [SEP] A size B height C impetus D ambitions  [SEP] C\n",
            "TOKEN:  ['a', 'force', 'acting', 'on', 'an', 'object', 'in', 'the', 'opposite', 'direction', 'that', 'the', 'object', 'is', 'moving', 'can', 'cause', 'that', \"object's\", 'speed', 'to', 'decrease', 'in', 'a', 'forward', 'motion', '[SEP]', 'pushing', 'against', 'a', 'rolling', 'boulder', 'will', 'decrease', 'its', '[SEP]', 'A', 'size', 'B', 'height', 'C', 'impetus', 'D', 'ambitions', '', '[SEP]', 'CURRENT']\n",
            "Valid Average Accuracy: 0.988\n",
            "0 / 500\n",
            "PRED:  [SEP]\n",
            "REAL:  A\n",
            "OBS:  force causes the speed of an object to decrease [SEP] The amount of friction and the speed of an object have what kind of relationship? [SEP] A inverse B reverse C direct D equal  [SEP] A\n",
            "TOKEN:  ['force', 'causes', 'the', 'speed', 'of', 'an', 'object', 'to', 'decrease', '[SEP]', 'The', 'amount', 'of', 'friction', 'and', 'the', 'speed', 'of', 'an', 'object', 'have', 'what', 'kind', 'of', 'relationship?', '[SEP]', 'A', 'inverse', 'B', 'reverse', 'C', 'direct', 'D', 'equal', '', '[SEP]', 'Aforce']\n",
            "100 / 500\n",
            "PRED:  [SEP]\n",
            "REAL:  C\n",
            "OBS:  a desert environment is dry [SEP] Where would a duck like to live? [SEP] A the Sahara B Antarctica C the Appalachian mountains D Death Valley  [SEP] C\n",
            "TOKEN:  ['a', 'desert', 'environment', 'is', 'dry', '[SEP]', 'Where', 'would', 'a', 'duck', 'like', 'to', 'live?', '[SEP]', 'A', 'the', 'Sahara', 'B', 'Antarctica', 'C', 'the', 'Appalachian', 'mountains', 'D', 'Death', 'Valley', '', '[SEP]', 'Cinder']\n",
            "PRED:  [SEP]\n",
            "REAL:  B\n",
            "OBS:  some adult animals lay eggs [SEP] is it normal for an adult animal to lay eggs? [SEP] A it has never happened B yes it is standard C it is abnormal and weird D all of these  [SEP] B\n",
            "TOKEN:  ['some', 'adult', 'animals', 'lay', 'eggs', '[SEP]', 'is', 'it', 'normal', 'for', 'an', 'adult', 'animal', 'to', 'lay', 'eggs?', '[SEP]', 'A', 'it', 'has', 'never', 'happened', 'B', 'yes', 'it', 'is', 'standard', 'C', 'it', 'is', 'abnormal', 'and', 'weird', 'D', 'all', 'of', 'these', '', '[SEP]', 'Bcats']\n",
            "PRED:  [SEP]\n",
            "REAL:  D\n",
            "OBS:  most canyons are formed by flowing rivers through erosion over long periods of time [SEP] The sides of the canyon are [SEP] A metal B water C rivers D stone  [SEP] D\n",
            "TOKEN:  ['most', 'canyons', 'are', 'formed', 'by', 'flowing', 'rivers', 'through', 'erosion', 'over', 'long', 'periods', 'of', 'time', '[SEP]', 'The', 'sides', 'of', 'the', 'canyon', 'are', '[SEP]', 'A', 'metal', 'B', 'water', 'C', 'rivers', 'D', 'stone', '', '[SEP]', 'Dhawks']\n",
            "200 / 500\n",
            "PRED:  [SEP]\n",
            "REAL:  A\n",
            "OBS:  crop rotation is when different crops are planted on a field in different years [SEP] Bill planted rapeseed in his field one year and soybeans the next in order to [SEP] A get bigger yields B make things boring C keep things random D get smaller yields  [SEP] A\n",
            "TOKEN:  ['crop', 'rotation', 'is', 'when', 'different', 'crops', 'are', 'planted', 'on', 'a', 'field', 'in', 'different', 'years', '[SEP]', 'Bill', 'planted', 'rapeseed', 'in', 'his', 'field', 'one', 'year', 'and', 'soybeans', 'the', 'next', 'in', 'order', 'to', '[SEP]', 'A', 'get', 'bigger', 'yields', 'B', 'make', 'things', 'boring', 'C', 'keep', 'things', 'random', 'D', 'get', 'smaller', 'yields', '', '[SEP]', 'Acrop']\n",
            "PRED:  [SEP]\n",
            "REAL:  C\n",
            "OBS:  the ocean contains large amounts of salt water [SEP] Which of the following contains large amounts of salt water? [SEP] A The Amazon B The Nile C The Indian D The Mississippi  [SEP] C\n",
            "TOKEN:  ['the', 'ocean', 'contains', 'large', 'amounts', 'of', 'salt', 'water', '[SEP]', 'Which', 'of', 'the', 'following', 'contains', 'large', 'amounts', 'of', 'salt', 'water?', '[SEP]', 'A', 'The', 'Amazon', 'B', 'The', 'Nile', 'C', 'The', 'Indian', 'D', 'The', 'Mississippi', '', '[SEP]', 'Cologne']\n",
            "300 / 500\n",
            "400 / 500\n",
            "Test Average Accuracy: 0.988\n"
          ]
        }
      ]
    }
  ]
}