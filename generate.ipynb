{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxxtRFQ+33sHLqMBuEI5N9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zarif123/497-DLNLP-HW2/blob/main/generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "y5jS5E2vdj5q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGdO1Lv7c7R8"
      },
      "outputs": [],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertModel, GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import json\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "G9ArM1zjdBrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Loop"
      ],
      "metadata": {
        "id": "VSk0wgh4d01r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, linear, optimizer, tokenizer, train, num_choices, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        train_len = len(train)\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for train_i in range(train_len):\n",
        "            observation = train[train_i]\n",
        "            contexts = []\n",
        "            labels = []\n",
        "            mask = torch.zeros((4, 2), dtype=float).to(device) ##### if code doesnt work, change to numpy\n",
        "\n",
        "            for choice_i in range(num_choices):\n",
        "                context = observation[choice_i][0]\n",
        "                label = observation[choice_i][1]\n",
        "                contexts.append(context)\n",
        "                labels.append(label)\n",
        "                mask[choice_i][label] = 1\n",
        "            \n",
        "            inputs = tokenizer(contexts, max_length=256, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            hidden = model(inputs)\n",
        "\n",
        "            logits = torch.matmul(hidden.last_hidden_state[:, 0, :], linear)\n",
        "            probs = torch.Softmax(logits, dim=1)\n",
        "            correct_probs = probs * mask\n",
        "            log_probs = torch.log(torch.sum(correct_probs, dim=1)).squeeze()\n",
        "            loss = -torch.sum(log_probs)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        average_loss = total_loss / train_len\n",
        "        print(f\"Epoch {epoch} Average Loss: {average_loss}\")"
      ],
      "metadata": {
        "id": "RagDk-a1dboo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate"
      ],
      "metadata": {
        "id": "3TzEZZdEgS76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, prompt, tokenizer):\n",
        "  tokenized_prompt = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "  tokenized_prompt = tokenized_prompt.to(device)\n",
        "\n",
        "  generated_outputs = model.generate(\n",
        "                                tokenized_prompt, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "  \n",
        "  for i, sample_output in enumerate(generated_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "1OTbFcg1gSDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find device"
      ],
      "metadata": {
        "id": "pXGRWtRUdt1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "0VtMIa0Udvfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "0Tg57l_Gdxl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():  \n",
        "    torch.manual_seed(0)\n",
        "    answers = ['A','B','C','D']\n",
        "\n",
        "    train = []\n",
        "    test = []\n",
        "    valid = []\n",
        "    \n",
        "    file_name = 'train_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem']\n",
        "        ans = answers.index(result['answerKey'])\n",
        "        \n",
        "        obs = []\n",
        "        for j in range(4):\n",
        "            text = base + result['question']['choices'][j]['text'] + ' [SEP]'\n",
        "            if j == ans:\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 0\n",
        "            obs.append([text,label])\n",
        "        train.append(obs)\n",
        "        \n",
        "        # print(obs)\n",
        "        # print(' ')\n",
        "        \n",
        "        # print(result['question']['stem'])\n",
        "        # print(' ',result['question']['choices'][0]['label'],result['question']['choices'][0]['text'])\n",
        "        # print(' ',result['question']['choices'][1]['label'],result['question']['choices'][1]['text'])\n",
        "        # print(' ',result['question']['choices'][2]['label'],result['question']['choices'][2]['text'])\n",
        "        # print(' ',result['question']['choices'][3]['label'],result['question']['choices'][3]['text'])\n",
        "        # print('  Fact: ',result['fact1'])\n",
        "        # print('  Answer: ',result['answerKey'])\n",
        "        # print('  ')\n",
        "                \n",
        "    file_name = 'dev_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem']\n",
        "        ans = answers.index(result['answerKey'])\n",
        "        \n",
        "        obs = []\n",
        "        for j in range(4):\n",
        "            text = base + result['question']['choices'][j]['text'] + ' [SEP]'\n",
        "            if j == ans:\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 0\n",
        "            obs.append([text,label])\n",
        "        valid.append(obs)\n",
        "        \n",
        "    file_name = 'test_complete.jsonl'        \n",
        "    with open(file_name) as json_file:\n",
        "        json_list = list(json_file)\n",
        "    for i in range(len(json_list)):\n",
        "        json_str = json_list[i]\n",
        "        result = json.loads(json_str)\n",
        "        \n",
        "        base = result['fact1'] + ' [SEP] ' + result['question']['stem']\n",
        "        ans = answers.index(result['answerKey'])\n",
        "        \n",
        "        obs = []\n",
        "        for j in range(4):\n",
        "            text = base + result['question']['choices'][j]['text'] + ' [SEP]'\n",
        "            if j == ans:\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 0\n",
        "            obs.append([text,label])\n",
        "        test.append(obs)\n",
        "\n",
        "    generate_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    generate_model = GPT2Model.from_pretrained('gpt2')\n",
        "    generate_optimizer = optim.Adam(generate_model.parameters(), lr=3e-5)\n",
        "    generate_linear = torch.rand(768,2)\n",
        "\n",
        "    train_loop(generate_model, generate_linear, generate_optimizer, generate_tokenizer, train, 4, 5)"
      ],
      "metadata": {
        "id": "4W8kZfBOdHcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "mFL7lsp-dZJV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}